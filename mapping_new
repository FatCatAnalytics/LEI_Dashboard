import asyncio
import aiohttp
import pandas as pd
import logging
from sentence_transformers import SentenceTransformer, util
import urllib.parse

# Setup logging
logging.basicConfig(level=logging.INFO)

# Load the fine-tuned model
model_path = 'fine-tuned-model'
model = SentenceTransformer(model_path)

# Asynchronous function to fetch data from the API with retry mechanism
async def fetch_company_data(session, name, retries=3, backoff_factor=2):
    encoded_company_name = urllib.parse.quote(name)
    url = f"https://api.gleif.org/api/v1/lei-records?page[size]=50&page[number]=1&filter[entity.names]={encoded_company_name}"
    for attempt in range(retries):
        try:
            async with session.get(url) as response:
                logging.info(f"Fetching data for {name} - Status: {response.status}")
                if response.status == 429:
                    logging.warning(f"Rate limit exceeded for {name}. Pausing for 5 seconds...")
                    await asyncio.sleep(5)  # Pause for 5 seconds
                    logging.warning(f"Retrying for {name}...")
                    await asyncio.sleep(backoff_factor * (2 ** attempt))
                    continue
                response.raise_for_status()
                data = await response.json()
                return name, data
        except aiohttp.ClientError as e:
            logging.error(f"Error fetching data for {name}: {e}")
            if attempt == retries - 1:
                return name, None
            await asyncio.sleep(backoff_factor * (2 ** attempt))
    return name, None

# Asynchronous function to process a list of company names
async def fetch_all_companies(names):
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_company_data(session, name) for name in names]
        results = await asyncio.gather(*tasks)
        return results

# Function to get SentenceTransformer embeddings
def get_bert_embedding(text):
    return model.encode(text, convert_to_tensor=True)

# Function to calculate cosine similarity using SentenceTransformer
def cosine_similarity_torch(vec1, vec2):
    return util.pytorch_cos_sim(vec1, vec2).item()

# Function to process and flatten the fetched data into a DataFrame
def process_results(results):
    records = []
    for name, data in results:
        if data and 'data' in data:
            for entry in data['data']:
                attributes = entry.get('attributes', {})
                entity_name = attributes.get('entity', {}).get('legalName', {}).get('name', 'N/A')
                lei = attributes.get('lei', 'N/A')
                address = attributes.get('entity', {}).get('legalAddress', {}).get('addressLines', ['N/A'])
                city = attributes.get('entity', {}).get('legalAddress', {}).get('city', 'N/A')
                country = attributes.get('entity', {}).get('legalAddress', {}).get('country', 'N/A')

                # Calculate BERT similarity score between the query name and the matched entity name
                query_embedding = get_bert_embedding(name)
                entity_embedding = get_bert_embedding(entity_name)
                similarity = cosine_similarity_torch(query_embedding, entity_embedding)

                # Additional features for ranking
                exact_match = 1 if name.lower() == entity_name.lower() else 0
                length_difference = abs(len(name) - len(entity_name))

                # Only add records where the matched entity name starts with the query name
                if entity_name.lower().startswith(name.lower()):
                    records.append({
                        "Query Name": name,
                        "Matched Entity Name": entity_name,
                        "LEI": lei,
                        "Address": ', '.join(address),
                        "City": city,
                        "Country": country,
                        "Similarity Score": similarity,
                        "Exact Match": exact_match,
                        "Length Difference": length_difference
                    })
        else:
            logging.warning(f"No data found for {name}")

    df = pd.DataFrame(records)
    return df

# Main function to fetch and process company data
def map_main(names):
    loop = asyncio.get_event_loop()
    results = loop.run_until_complete(fetch_all_companies(names))
    df = process_results(results).sort_values(by=["Similarity Score", "Exact Match", "Length Difference"], ascending=[False, False, True])
    return df

# Example usage
""" if __name__ == "__main__":
    company_names = ["Apple", "Google llc", "Microsoft"]
    result_df = main(company_names)

    # Sort the DataFrame by similarity score, exact match, and length difference
    result_df_sorted = result_df.sort_values(by=["Exact Match", "Similarity Score", "Length Difference"], ascending=[False, False, True])

    # Print the sorted results
    print(result_df_sorted) """
